name: Weekly Processing Pipeline

on:
  schedule:
    # Run at 10 AM UTC every Sunday
    - cron: '0 10 * * 0'
  workflow_dispatch:
    inputs:
      week:
        description: 'Week to process (YYYY-WXX, e.g., 2024-W31)'
        required: false
        type: string

env:
  PYTHON_VERSION: '3.12'

jobs:
  process-weekly-data:
    runs-on: ubuntu-latest
    timeout-minutes: 180  # 3 hour timeout for weekly batches
    
    steps:
    - name: ðŸ“¥ Checkout Repository
      uses: actions/checkout@v4
      
    - name: ðŸ Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        
    - name: ðŸ“¦ Install Dependencies
      run: |
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install google-api-python-client google-auth google-auth-httplib2 google-auth-oauthlib python-dotenv
        
    - name: ðŸ”‘ Setup Credentials
      env:
        GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_DRIVE_SERVICE_ACCOUNT }}
      run: |
        mkdir -p .credentials
        echo "$GOOGLE_CREDENTIALS" | base64 -d > .credentials/google-drive-service-account.json
        chmod 600 .credentials/google-drive-service-account.json
        
    - name: ðŸ”§ Create Environment Configuration
      run: |
        cat > .env << EOF
        GOOGLE_DRIVE_SERVICE_ACCOUNT=.credentials/google-drive-service-account.json
        DAILY_FOLDER_ID=${{ secrets.DAILY_FOLDER_ID }}
        WEEKLY_FOLDER_ID=${{ secrets.WEEKLY_FOLDER_ID }}
        GITHUB_USERNAME=${{ github.repository_owner }}
        TRADINGVIEW_NAMESPACE=${{ secrets.TRADINGVIEW_NAMESPACE }}
        PROCESSING_MODE=production
        MAX_FILES_PER_BATCH=100
        PARALLEL_WORKERS=4
        SLACK_WEBHOOK_URL=${{ secrets.SLACK_WEBHOOK_URL }}
        DISCORD_WEBHOOK_URL=${{ secrets.DISCORD_WEBHOOK_URL }}
        EOF
        
    - name: ðŸ“… Set Processing Week
      id: week
      run: |
        if [ -n "${{ github.event.inputs.week }}" ]; then
          echo "WEEK=${{ github.event.inputs.week }}" >> $GITHUB_OUTPUT
        else
          # Calculate current week in YYYY-WXX format
          echo "WEEK=$(date -u +'%Y-W%V')" >> $GITHUB_OUTPUT
        fi
        echo "Processing week: $(cat $GITHUB_OUTPUT)"
        
    - name: ðŸ“¥ Process Weekly Data
      run: |
        # Create a modified version of process_from_drive.py for weekly
        python -c "
        import os
        import sys
        import json
        import io
        from datetime import datetime
        from google.oauth2 import service_account
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaIoBaseDownload
        from dotenv import load_dotenv
        import subprocess
        
        load_dotenv()
        
        # Download from weekly folder
        service_account_file = os.getenv('GOOGLE_DRIVE_SERVICE_ACCOUNT')
        folder_id = os.getenv('WEEKLY_FOLDER_ID')
        week_str = '${{ steps.week.outputs.WEEK }}'
        
        print(f'Processing weekly data for {week_str}')
        
        credentials = service_account.Credentials.from_service_account_file(
            service_account_file,
            scopes=['https://www.googleapis.com/auth/drive.readonly']
        )
        
        service = build('drive', 'v3', credentials=credentials)
        local_dir = f'data/raw/weekly/{week_str}'
        os.makedirs(local_dir, exist_ok=True)
        
        # Download files
        results = service.files().list(
            q=f\"'{folder_id}' in parents\",
            pageSize=1000,
            fields='files(id, name, size)'
        ).execute()
        
        files = results.get('files', [])
        print(f'Found {len(files)} files')
        
        for file in files:
            if file['name'].endswith('.json'):
                print(f'Downloading: {file[\"name\"]}')
                request = service.files().get_media(fileId=file['id'])
                file_path = os.path.join(local_dir, file['name'])
                
                fh = io.BytesIO()
                downloader = MediaIoBaseDownload(fh, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                
                with open(file_path, 'wb') as f:
                    f.write(fh.getvalue())
        
        # Process the batch
        result = subprocess.run([
            sys.executable,
            'src/batch_processing/batch_processor.py',
            '--timeframe', 'weekly',
            '--date', week_str
        ], capture_output=True, text=True)
        
        print(result.stdout)
        if result.returncode != 0:
            print(result.stderr)
            sys.exit(1)
        "
        
    - name: ðŸ” Verify Output
      run: |
        echo "Checking output directory..."
        ls -la data/output/weekly/${{ steps.week.outputs.WEEK }}/ || echo "No output found"
        
    - name: ðŸ“Š Prepare GitHub Pages Deployment
      if: success()
      run: |
        mkdir -p docs/data/weekly
        if [ -d "data/output/weekly/${{ steps.week.outputs.WEEK }}" ]; then
          cp -r data/output/weekly/${{ steps.week.outputs.WEEK }}/* docs/data/weekly/
          echo "Copied $(ls -1 data/output/weekly/${{ steps.week.outputs.WEEK }}/*.csv | wc -l) CSV files"
        fi
        
    - name: ðŸš€ Deploy to GitHub Pages
      if: success()
      uses: peaceiris/actions-gh-pages@v3
      with:
        github_token: ${{ secrets.GITHUB_TOKEN }}
        publish_branch: gh-pages
        publish_dir: ./data/output/weekly/${{ steps.week.outputs.WEEK }}
        destination_dir: data/weekly
        keep_files: true
        
    - name: ðŸ“Š Generate Summary
      if: always()
      run: |
        echo "## Weekly Processing Summary" >> $GITHUB_STEP_SUMMARY
        echo "- Week: ${{ steps.week.outputs.WEEK }}" >> $GITHUB_STEP_SUMMARY
        echo "- Status: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
        if [ -d "data/output/weekly/${{ steps.week.outputs.WEEK }}" ]; then
          echo "- Files processed: $(ls -1 data/output/weekly/${{ steps.week.outputs.WEEK }}/*.csv 2>/dev/null | wc -l)" >> $GITHUB_STEP_SUMMARY
        fi